# AI Assistant Framework

FastAPI + LangGraph ê¸°ë°˜ AI Agent ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë¹ ë¥´ê²Œ êµ¬ì¶•í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬

Hexagonal Architecture, Port-Adapter Pattern, ë°ì½”ë ˆì´í„° ê¸°ë°˜ ì˜ì¡´ì„± ì£¼ì…, í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ë¥¼ ê¸°ë³¸ ì œê³µí•©ë‹ˆë‹¤.

**ì´ ë ˆí¬ì§€í† ë¦¬ëŠ” ì²« ë²ˆì§¸ í…œí”Œë¦¿ì¸ `cooking-assistant` ì˜ˆì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.**

---

## í•µì‹¬ íŠ¹ì§•

### ì•„í‚¤í…ì²˜
- **Hexagonal Architecture** - Port-Adapter íŒ¨í„´ìœ¼ë¡œ ì™¸ë¶€ ì‹œìŠ¤í…œ êµì²´ ê°€ëŠ¥
- **Pure Port ì›ì¹™** - AdapterëŠ” API í˜¸ì¶œë§Œ, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì€ Application Layerê°€ ë‹´ë‹¹
- **ë°ì½”ë ˆì´í„° ê¸°ë°˜ DI** - @singleton, @injectë¡œ ëª…ì‹œì  ì˜ì¡´ì„± ê´€ë¦¬

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸
- **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬** - YAML ê¸°ë°˜ ë²„ì „ ê´€ë¦¬ ë° Jinja2 í…œí”Œë¦¿
- **JWT ì¸ì¦** - ì„ íƒì /í•„ìˆ˜ ì¸ì¦ ì „ëµ ì§€ì›
- **LangGraph Workflow** - AI Agent ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- **ë©€í‹° Adapter** - LLM(Anthropic, OpenAI), Image(Replicate, DALL-E) ë“± êµì²´ ê°€ëŠ¥

---

## ë¹ ë¥¸ ì‹œì‘

### ì„¤ì¹˜

```bash
git clone https://github.com/your-username/ai-assistant-framework.git
cd ai-assistant-framework
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ API í‚¤ ì¶”ê°€
```

### ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# ì„œë²„ ì‹¤í–‰ (í•« ë¦¬ë¡œë“œ í¬í•¨)
uvicorn app.main:app --reload
```

- ì„œë²„: http://localhost:8000
- API ë¬¸ì„œ: http://localhost:8000/docs
- ì¢…ë£Œ: Ctrl+C

---

## í”„ë ˆì„ì›Œí¬ ì•„í‚¤í…ì²˜

### ê³„ì¸µ êµ¬ì¡°

```
API Routes â†’ Services â†’ Workflow â†’ Nodes â†’ Adapters â†’ External APIs
             â†“
          Entities
```

### Port-Adapter Pattern

**Coreì˜ ì—­í• :**
- Port ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (ILLMPort, IImagePort)
- Adapter êµ¬í˜„ì²´ ì œê³µ (êµì²´ ê°€ëŠ¥)
- Applicationì€ Portë§Œ ì˜ì¡´

**Pure Adapter ì›ì¹™:**
```python
# âŒ Bad: Adapterì— ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
class BadAdapter(ILLMPort):
    async def generate_recipe(self, query: str):
        # í”„ë¡¬í”„íŠ¸ ì„ íƒ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§! (X)
        prompt = self.select_prompt(query)
        return self.llm.invoke(prompt)

# âœ… Good: AdapterëŠ” API í˜¸ì¶œë§Œ
class GoodAdapter(ILLMPort):
    async def generate_recipe(self, prompt: str):
        # ë Œë”ë§ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ APIë§Œ í˜¸ì¶œ
        return self.llm.invoke(prompt)
```

### ì˜ì¡´ì„± ì£¼ì…

ë°ì½”ë ˆì´í„° ê¸°ë°˜ DI ì‚¬ìš©:

```python
from app.core.decorators import singleton, inject

@singleton
class RecipeGeneratorNode(BaseNode):
    @inject
    def __init__(self, llm_port: ILLMPort, prompt_loader: PromptLoader):
        self.llm_port = llm_port
        self.prompt_loader = prompt_loader

    async def execute(self, state):
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: í”„ë¡¬í”„íŠ¸ ì„ íƒ
        prompt_id = "cooking.generate_recipe_single"

        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: í”„ë¡¬í”„íŠ¸ ë Œë”ë§
        prompt = self.prompt_loader.render(prompt_id, query=state["user_query"])

        # Adapter: ìˆœìˆ˜ API í˜¸ì¶œë§Œ
        recipe = await self.llm_port.generate_recipe(prompt)
        return recipe
```

Port-Adapter ë°”ì¸ë”© (Application Module):

```python
# app/cooking_assistant/module.py
class CookingModule(Module):
    @provider
    def provide_llm_adapter(self, settings: Settings) -> ILLMPort:
        return AnthropicLLMAdapter(settings)  # êµì²´ ê°€ëŠ¥
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
app/
â”œâ”€â”€ core/                            # ğŸ”§ í”„ë ˆì„ì›Œí¬ Core (ì¬ì‚¬ìš© ê°€ëŠ¥)
â”‚   â”œâ”€â”€ config.py                   # ì„¤ì • ê´€ë¦¬ (ë²”ìš©)
â”‚   â”œâ”€â”€ auth.py                     # JWT ì¸ì¦ (ë²”ìš©)
â”‚   â”œâ”€â”€ prompt_loader.py            # í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ (ë²”ìš©)
â”‚   â”œâ”€â”€ decorators.py               # DI ë°ì½”ë ˆì´í„° (ë²”ìš©)
â”‚   â”œâ”€â”€ dependencies.py             # FastAPI Dependencies (ë²”ìš©)
â”‚   â”œâ”€â”€ ports/                      # Port ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ llm_port.py            # ILLMPort (ë²”ìš© ì¸í„°í˜ì´ìŠ¤)
â”‚   â”‚   â””â”€â”€ image_port.py          # IImagePort (ë²”ìš© ì¸í„°í˜ì´ìŠ¤)
â”‚   â””â”€â”€ adapters/                   # Adapter êµ¬í˜„ì²´
â”‚       â”œâ”€â”€ llm/
â”‚       â”‚   â””â”€â”€ anthropic_adapter.py
â”‚       â””â”€â”€ image/
â”‚           â””â”€â”€ replicate_adapter.py
â”‚
â”œâ”€â”€ cooking_assistant/               # ğŸ“¦ Application Template (ë„ë©”ì¸ íŠ¹í™”)
â”‚   â”œâ”€â”€ module.py                   # DI ë°”ì¸ë”© (í…œí”Œë¦¿ë³„)
â”‚   â”œâ”€â”€ entities/                   # ë„ë©”ì¸ ì—”í‹°í‹°
â”‚   â”‚   â”œâ”€â”€ recipe.py
â”‚   â”‚   â”œâ”€â”€ recommendation.py
â”‚   â”‚   â””â”€â”€ question.py
â”‚   â”œâ”€â”€ models/                     # DTO & Response ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ response_codes.py
â”‚   â”œâ”€â”€ services/                   # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤
â”‚   â”‚   â””â”€â”€ cooking_service.py
â”‚   â”œâ”€â”€ workflow/                   # LangGraph Workflow
â”‚   â”‚   â”œâ”€â”€ cooking_workflow.py
â”‚   â”‚   â”œâ”€â”€ states/
â”‚   â”‚   â”‚   â””â”€â”€ cooking_state.py
â”‚   â”‚   â”œâ”€â”€ nodes/                  # Workflow Nodes
â”‚   â”‚   â”‚   â”œâ”€â”€ base_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ intent_classifier_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ recipe_generator_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ recommender_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ question_answerer_node.py
â”‚   â”‚   â”‚   â””â”€â”€ image_generator_node.py
â”‚   â”‚   â””â”€â”€ edges/                  # Workflow Edges
â”‚   â”‚       â””â”€â”€ intent_router.py
â”‚   â”œâ”€â”€ api/                        # API Routes
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”œâ”€â”€ prompts/                    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚   â”‚   â””â”€â”€ cooking.yaml
â”‚   â””â”€â”€ exceptions.py               # ë„ë©”ì¸ ì˜ˆì™¸
â”‚
â””â”€â”€ main.py                          # FastAPI ì•± ì§„ì…ì 
```

### êµ¬ì¡° ì„¤ëª…

**Core (í”„ë ˆì„ì›Œí¬):**
- ëª¨ë“  Applicationì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥
- ë„ë©”ì¸ ë¬´ê´€, ìˆœìˆ˜ ê¸°ìˆ  ì¸í”„ë¼
- Port ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- Adapter êµ¬í˜„ì²´ ì œê³µ

**Application Template (cooking_assistant):**
- íŠ¹ì • ë„ë©”ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
- Coreì˜ Portë¥¼ í™œìš©
- í…œí”Œë¦¿ë³„ë¡œ ë…ë¦½ì 

---

## ì„¤ê³„ ì›ì¹™

### 1. Port-Adapter Pattern

**Port (ì¸í„°í˜ì´ìŠ¤):**
```python
# app/core/ports/llm_port.py
class ILLMPort(ABC):
    @abstractmethod
    async def classify_intent(self, prompt: str) -> Dict[str, Any]:
        """ë Œë”ë§ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ LLM API í˜¸ì¶œ"""
        pass
```

**Adapter (êµ¬í˜„ì²´):**
```python
# app/core/adapters/llm/anthropic_adapter.py
@singleton
class AnthropicLLMAdapter(ILLMPort):
    async def classify_intent(self, prompt: str) -> Dict[str, Any]:
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return json.loads(self._extract_json(response.content))
```

**êµì²´ ê°€ëŠ¥:**
```python
# OpenAIë¡œ êµì²´
class OpenAIAdapter(ILLMPort):
    async def classify_intent(self, prompt: str) -> Dict[str, Any]:
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return json.loads(response.choices[0].message.content)
```

### 2. Pure Adapter ì›ì¹™

**Adapterì˜ ì±…ì„:**
- âœ… API í˜¸ì¶œ
- âœ… ê²°ê³¼ íŒŒì‹± (JSON â†’ Dict)
- âŒ í”„ë¡¬í”„íŠ¸ ì„ íƒ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
- âŒ í”„ë¡¬í”„íŠ¸ ë Œë”ë§ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
- âŒ ì—”í‹°í‹° ë³€í™˜ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)

**í˜¸ì¶œì(Node, Service)ì˜ ì±…ì„:**
- âœ… í”„ë¡¬í”„íŠ¸ ì„ íƒ
- âœ… í”„ë¡¬í”„íŠ¸ ë Œë”ë§
- âœ… ì—”í‹°í‹° ë³€í™˜ ë° ê²€ì¦

### 3. ë ˆì´ì–´ë³„ ì±…ì„

**API Layer (Routes):**
- HTTP ìš”ì²­/ì‘ë‹µ ì²˜ë¦¬
- ì¸ì¦ í™•ì¸
- Service í˜¸ì¶œ

**Service Layer:**
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¡°í•©
- Workflow ì‹¤í–‰
- Entity â†’ DTO ë³€í™˜

**Workflow Layer:**
- ë…¸ë“œ ì‹¤í–‰ ìˆœì„œ ì •ì˜
- State ê´€ë¦¬

**Node Layer:**
- í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° ë Œë”ë§
- Portë¥¼ í†µí•œ ì™¸ë¶€ API í˜¸ì¶œ
- ê²°ê³¼ë¥¼ Entityë¡œ ë³€í™˜

**Adapter Layer:**
- ìˆœìˆ˜ API í˜¸ì¶œ ë° íŒŒì‹±ë§Œ

---

## Secondary Intent ì²˜ë¦¬

ì´ í”„ë ˆì„ì›Œí¬ëŠ” **ë³µí•© ì˜ë„ ì²˜ë¦¬**ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

### ì˜ˆì‹œ
```
ì‚¬ìš©ì ì¿¼ë¦¬: "ë§¤ìš´ ìŒì‹ ì¶”ì²œí•´ì£¼ê³ , ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ë„ ì•Œë ¤ì¤˜"

ë¶„ë¥˜ ê²°ê³¼:
- primary_intent: "recommend"
- secondary_intents: ["recipe_create"]

ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìˆœì„œ:
1. Recommender Node (primary) â†’ ì¶”ì²œ ëª©ë¡ ìƒì„±
2. Recipe Generator Node (secondary) â†’ ë ˆì‹œí”¼ ìƒì„±

ìµœì¢… ì‘ë‹µ:
{
  "code": "RECOMMENDATION_SUCCESS",
  "data": {
    "recommendations": [...],
    "secondary_results": [
      {
        "intent": "recipe_create",
        "recipe": {...}
      }
    ]
  }
}
```

### êµ¬í˜„ ë°©ì‹

**1. BaseNodeì—ì„œ ìë™ ì²˜ë¦¬:**
```python
# app/cooking_assistant/workflow/nodes/base_node.py
class BaseNode(ABC):
    def _handle_secondary_intent(self, state: CookingState):
        if secondary_intents and secondary_intents[0] == self.intent_name:
            processed_intent = secondary_intents.pop(0)
            state["processed_secondary_intents"].append(processed_intent)
```

**2. Serviceì—ì„œ ê²°ê³¼ ìˆ˜ì§‘:**
```python
# app/cooking_assistant/services/cooking_service.py
def _to_dto(self, state: CookingState):
    # Primary intent ì‘ë‹µ ìƒì„±
    response = self._create_response_by_intent(state["primary_intent"], state)

    # Secondary intents ê²°ê³¼ ìˆ˜ì§‘
    secondary_results = self._collect_secondary_results(state)

    # ì‘ë‹µì— ì¶”ê°€
    response.data.secondary_results = secondary_results
    return response
```

---

## ê¸°ìˆ  ìŠ¤íƒ

- **Web Framework:** FastAPI
- **Workflow Engine:** LangGraph
- **AI/LLM:** Anthropic Claude Sonnet 4.5
- **Image Generation:** Replicate Flux Schnell
- **Authentication:** JWT (python-jose)
- **Dependency Injection:** injector
- **Prompt Management:** YAML + Jinja2
- **Configuration:** pydantic-settings

---

## ì˜ˆì œ: Cooking Assistant í…œí”Œë¦¿

ì´ ë ˆí¬ì§€í† ë¦¬ëŠ” ì²« ë²ˆì§¸ í…œí”Œë¦¿ì¸ **í•œêµ­ì–´ ìš”ë¦¬ AI ì–´ì‹œìŠ¤í„´íŠ¸** ì˜ˆì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

### ê¸°ëŠ¥
- **ë ˆì‹œí”¼ ìƒì„±** - ì¡°ë¦¬ë²•ê³¼ ì´ë¯¸ì§€ ìë™ ìƒì„±
- **ìŒì‹ ì¶”ì²œ** - ë§ì¶¤í˜• ë©”ë‰´ ì œì•ˆ
- **ìš”ë¦¬ Q&A** - ìš”ë¦¬ ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€
- **ë³µí•© ì˜ë„ ì²˜ë¦¬** - í•˜ë‚˜ì˜ ì¿¼ë¦¬ë¡œ ì—¬ëŸ¬ ì‘ì—… ìˆ˜í–‰
- **í•œêµ­ì–´ ë„¤ì´í‹°ë¸Œ ì§€ì›**

### API ì‚¬ìš© ì˜ˆì œ

**ë ˆì‹œí”¼ ìƒì„±:**
```bash
curl -X POST http://localhost:8000/api/cooking \
  -H "Content-Type: application/json" \
  -d '{"query": "ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²•"}'
```

**ìŒì‹ ì¶”ì²œ:**
```bash
curl -X POST http://localhost:8000/api/cooking \
  -H "Content-Type: application/json" \
  -d '{"query": "ë§¤ìš´ ìŒì‹ ì¶”ì²œí•´ì¤˜"}'
```

**ë³µí•© ì˜ë„:**
```bash
curl -X POST http://localhost:8000/api/cooking \
  -H "Content-Type: application/json" \
  -d '{"query": "ë§¤ìš´ ìŒì‹ ì¶”ì²œí•´ì£¼ê³ , ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ë„ ì•Œë ¤ì¤˜"}'
```

**ì¸ì¦ ì‚¬ìš©:**
```bash
# í† í° ìƒì„±
python3 scripts/generate_token.py user123

# ì¸ì¦ëœ ìš”ì²­
curl -X POST http://localhost:8000/api/cooking \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <token>" \
  -d '{"query": "ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë²•"}'
```

---

## ìƒˆë¡œìš´ Application ë§Œë“¤ê¸°

### 1. Application íŒ¨í‚¤ì§€ ìƒì„±

```bash
mkdir -p app/my_app/{entities,models,services,workflow/{nodes,edges,states},api,prompts}
```

### 2. Module ì •ì˜

```python
# app/my_app/module.py
from injector import Module, singleton, provider
from app.core.ports.llm_port import ILLMPort
from app.core.adapters.llm.anthropic_adapter import AnthropicLLMAdapter

class MyAppModule(Module):
    @singleton
    @provider
    def provide_llm_adapter(self, settings: Settings) -> ILLMPort:
        return AnthropicLLMAdapter(settings)
```

### 3. Dependencies ìˆ˜ì •

```python
# app/core/dependencies.py
from app.my_app.module import MyAppModule

def get_injector() -> Injector:
    if _injector is None:
        _injector = Injector([MyAppModule()])  # ë³€ê²½
    return _injector
```

### 4. Entity, Service, Workflow êµ¬í˜„

ê¸°ì¡´ `cooking_assistant` íŒ¨í‚¤ì§€ë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬í˜„

---

## Adapter êµì²´í•˜ê¸°

### LLM Adapter êµì²´ (Anthropic â†’ OpenAI)

**1. OpenAI Adapter êµ¬í˜„:**
```python
# app/core/adapters/llm/openai_adapter.py
@singleton
class OpenAIAdapter(ILLMPort):
    @inject
    def __init__(self, settings: Settings):
        self.client = OpenAI(api_key=settings.openai_api_key)

    async def classify_intent(self, prompt: str) -> Dict[str, Any]:
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
```

**2. Moduleì—ì„œ ë°”ì¸ë”© ë³€ê²½:**
```python
# app/cooking_assistant/module.py
from app.core.adapters.llm.openai_adapter import OpenAIAdapter

class CookingModule(Module):
    @provider
    def provide_llm_adapter(self, settings: Settings) -> ILLMPort:
        return OpenAIAdapter(settings)  # ë³€ê²½!
```

**3. Config ìˆ˜ì •:**
```python
# app/core/config.py
class Settings(BaseSettings):
    openai_api_key: str  # ì¶”ê°€
```

ì™„ë£Œ! Application ì½”ë“œëŠ” ì „í˜€ ìˆ˜ì •í•  í•„ìš” ì—†ìŒ.

---

## í™˜ê²½ ë³€ìˆ˜

```bash
# .env
ANTHROPIC_API_KEY=sk-ant-...
REPLICATE_API_TOKEN=r8_...
SECRET_KEY=your-secret-key-here

# LLM ì„¤ì •
LLM_MODEL=claude-sonnet-4-5-20250929
LLM_TIMEOUT=90
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096

# ì´ë¯¸ì§€ ìƒì„± ì„¤ì •
IMAGE_MODEL=black-forest-labs/flux-schnell
IMAGE_RETRIES=2

# ì•± ì„¤ì •
APP_TITLE=AI Assistant API
APP_VERSION=2.0.0
LOG_LEVEL=INFO
```

---

## í–¥í›„ ê³„íš

### Application Templates
- **chatbot** - ëŒ€í™”í˜• ì±—ë´‡ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬)
- **rag-qa** - RAG ê¸°ë°˜ ë¬¸ì„œ Q&A (Vector DB ì—°ë™)
- **multimodal** - ë©€í‹°ëª¨ë‹¬ AI (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)

### Framework ê°œì„ 
- CLI ë„êµ¬ (í”„ë¡œì íŠ¸ ìŠ¤ìºí´ë”©)
- í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹°
- ì¶”ê°€ Adapter (OpenAI, Google Gemini, DALL-E ë“±)

---

## ë¼ì´ì„ ìŠ¤

MIT License
